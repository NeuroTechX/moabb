{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# MNE Epochs-based pipelines\n\nThis example shows how to use machine learning pipeline based on MNE Epochs\ninstead of Numpy arrays. This is useful to make the most of the MNE code base\nand to embed EEG specific code inside sklearn pipelines.\n\nWe will compare different pipelines for P300:\n- Logistic regression, based on MNE Epochs\n- XDAWN and Logistic Regression (LR), based on MNE Epochs\n- XDAWN extended covariance and LR on tangent space, based on Numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Sylvain Chevallier\n#\n# License: BSD (3-clause)\n# sphinx_gallery_thumbnail_number = 2\n\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom mne.decoding import Vectorizer\nfrom mne.preprocessing import Xdawn\nfrom pyriemann.estimation import XdawnCovariances\nfrom pyriemann.tangentspace import TangentSpace\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nimport moabb\nfrom moabb.analysis.meta_analysis import (  # noqa: E501\n    compute_dataset_statistics,\n    find_significant_differences,\n)\nfrom moabb.analysis.plotting import paired_plot, summary_plot\nfrom moabb.datasets import BNCI2014_009\nfrom moabb.evaluations import CrossSessionEvaluation\nfrom moabb.paradigms import P300\n\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\nwarnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\nmoabb.set_log_level(\"info\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Dataset\n\nLoad 2 subjects of BNCI 2014-009 dataset, with 3 session each\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = BNCI2014_009()\ndataset.subject_list = dataset.subject_list[:3]\ndatasets = [dataset]\nparadigm = P300()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Data (optional)\n\nTo get access to the EEG signals downloaded from the dataset, you could\nuse ``dataset.get_data([subject_id)`` to obtain the EEG as MNE Epochs, stored\nin a dictionary of sessions and runs.\nThe ``paradigm.get_data(dataset=dataset, subjects=[subject_id])`` allows to\nobtain the preprocessed EEG data, the labels and the meta information. By\ndefault, the EEG is return as a Numpy array. With ``return_epochs=True``, MNE\nEpochs are returned.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subject_list = [1]\nsessions = dataset.get_data(subject_list)\nX, labels, meta = paradigm.get_data(dataset=dataset, subjects=subject_list)\nepochs, labels, meta = paradigm.get_data(\n    dataset=dataset, subjects=subject_list, return_epochs=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A Simple MNE Pipeline\n\nUsing ``return_epochs=True`` in the evaluation, it is possible to design a\npipeline based on MNE Epochs input. Let's create a simple one, that\nreshape the input data from epochs, rescale the data and uses a logistic\nregression to classify the data. We will need to write a basic Transformer\nestimator, that complies with\n[sklearn convention](https://scikit-learn.org/stable/developers/develop.html).\nThis transformer will extract the data from an input Epoch, and reshapes into\n2D array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MyVectorizer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        arr = X.get_data()\n        self.features_shape_ = arr.shape[1:]\n        return self\n\n    def transform(self, X, y=None):\n        arr = X.get_data()\n        return arr.reshape(len(arr), -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will define a pipeline that is based on this new class, using a scaler\nand a logistic regression. This pipeline is evaluated across session using\nROC-AUC metric.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mne_ppl = {}\nmne_ppl[\"MNE LR\"] = make_pipeline(\n    MyVectorizer(), StandardScaler(), LogisticRegression(penalty=\"l1\", solver=\"liblinear\")\n)\n\nmne_eval = CrossSessionEvaluation(\n    paradigm=paradigm,\n    datasets=datasets,\n    suffix=\"examples\",\n    overwrite=True,\n    return_epochs=True,\n)\nmne_res = mne_eval.process(mne_ppl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced MNE Pipeline\n\nIn some case, the MNE pipeline should have access to the original labels from\nthe dataset. This is the case for the XDAWN code of MNE. One could pass\n`mne_labels` to evaluation in order to keep this label.\nAs an example, we will define a pipeline that computes an XDAWN filter, rescale,\nthen apply a logistic regression.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mne_adv = {}\nmne_adv[\"XDAWN LR\"] = make_pipeline(\n    Xdawn(n_components=5, reg=\"ledoit_wolf\", correct_overlap=False),\n    Vectorizer(),\n    StandardScaler(),\n    LogisticRegression(penalty=\"l1\", solver=\"liblinear\"),\n)\nadv_eval = CrossSessionEvaluation(\n    paradigm=paradigm,\n    datasets=datasets,\n    suffix=\"examples\",\n    overwrite=True,\n    return_epochs=True,\n    mne_labels=True,\n)\nadv_res = mne_eval.process(mne_adv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Numpy-based Pipeline\n\nFor the comparison, we will define a Numpy-based pipeline that relies on\npyriemann to estimate XDAWN-extended covariance matrices that are projected\non the tangent space and classified with a logistic regression.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sk_ppl = {}\nsk_ppl[\"RG LR\"] = make_pipeline(\n    XdawnCovariances(nfilter=5, estimator=\"lwf\", xdawn_estimator=\"scm\"),\n    TangentSpace(),\n    LogisticRegression(penalty=\"l1\", solver=\"liblinear\"),\n)\nsk_eval = CrossSessionEvaluation(\n    paradigm=paradigm,\n    datasets=datasets,\n    suffix=\"examples\",\n    overwrite=True,\n)\nsk_res = sk_eval.process(sk_ppl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combining Results\n\nEven if the results have been obtained by different evaluation processes, it\nis possible to combine the resulting DataFrames to analyze and plot the\nresults.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "all_res = pd.concat([mne_res, adv_res, sk_res])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We could compare the Euclidean and Riemannian performance using a `paired_plot`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "paired_plot(all_res, \"XDAWN LR\", \"RG LR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All the results could be compared and statistical analysis could highlight the\ndifferences between pipelines.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stats = compute_dataset_statistics(all_res)\nP, T = find_significant_differences(stats)\nsummary_plot(P, T)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}