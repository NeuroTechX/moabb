{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Cross-Subject SSVEP\nThis example shows how to perform a cross-subject analysis on an SSVEP dataset.\nWe will compare four pipelines :\n\n- Riemannian Geometry\n- CCA\n- TRCA\n- MsetCCA\n\nWe will use the SSVEP paradigm, which uses the AUC as metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Sylvain Chevallier <sylvain.chevallier@uvsq.fr>\n#\n# License: BSD (3-clause)\n\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom pyriemann.estimation import Covariances\nfrom pyriemann.tangentspace import TangentSpace\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\n\nimport moabb\nfrom moabb.datasets import Kalunga2016\nfrom moabb.evaluations import CrossSubjectEvaluation\nfrom moabb.paradigms import SSVEP, FilterBankSSVEP\nfrom moabb.pipelines import SSVEP_CCA, SSVEP_TRCA, ExtendedSSVEPSignal, SSVEP_MsetCCA\n\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\nwarnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\nmoabb.set_log_level(\"info\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Dataset\n\nWe will load the data from the first 2 subjects of the ``SSVEP_Exo`` dataset\nand compare two algorithms on this set. One of the algorithms could only\nprocess class associated with a stimulation frequency, we will thus drop\nthe resting class. As the resting class is the last defined class, picking\nthe first three classes (out of four) allows to focus only on the stimulation\nfrequency.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_subject = 2\ndataset = Kalunga2016()\ndataset.subject_list = dataset.subject_list[:n_subject]\ninterval = dataset.interval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choose Paradigm\n\nWe define the paradigms (SSVEP, SSVEP TRCA, SSVEP MsetCCA, and FilterBankSSVEP) and\nuse the dataset Kalunga2016. All 3 SSVEP paradigms applied a bandpass filter (10-42 Hz) on\nthe data, which include all stimuli frequencies and their first harmonics,\nwhile the FilterBankSSVEP paradigm uses as many bandpass filters as\nthere are stimulation frequencies (here 3). For each stimulation frequency\nthe EEG is filtered with a 1 Hz-wide bandpass filter centered on the\nfrequency. This results in ``n_classes`` copies of the signal, filtered for each\nclass, as used in the filterbank motor imagery paradigms.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "paradigm = SSVEP(fmin=10, fmax=42, n_classes=3)\nparadigm_TRCA = SSVEP(fmin=10, fmax=42, n_classes=3)\nparadigm_MSET_CCA = SSVEP(fmin=10, fmax=42, n_classes=3)\nparadigm_fb = FilterBankSSVEP(filters=None, n_classes=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classes are defined by the frequency of the stimulation, here we use\nthe first two frequencies of the dataset, 13 and 17 Hz.\nThe evaluation function uses a LabelEncoder, transforming them\nto 0 and 1\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "freqs = paradigm.used_events(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Pipelines\n\nPipelines must be a dict of sklearn pipeline transformer.\nThe first pipeline uses Riemannian geometry, by building an extended\ncovariance matrices from the signal filtered around the considered\nfrequency and applying a logistic regression in the tangent plane.\nThe second pipeline relies on the above defined CCA classifier.\nThe third pipeline relies on the TRCA algorithm,\nand the fourth uses the MsetCCA algorithm. Both CCA based methods\n(i.e. CCA and MsetCCA) used 3 CCA components.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipelines_fb = {}\npipelines_fb[\"RG+LogReg\"] = make_pipeline(\n    ExtendedSSVEPSignal(),\n    Covariances(estimator=\"lwf\"),\n    TangentSpace(),\n    LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n)\n\npipelines = {}\npipelines[\"CCA\"] = make_pipeline(SSVEP_CCA(interval=interval, freqs=freqs, n_harmonics=2))\n\npipelines_TRCA = {}\npipelines_TRCA[\"TRCA\"] = make_pipeline(SSVEP_TRCA(interval=interval, freqs=freqs))\n\npipelines_MSET_CCA = {}\npipelines_MSET_CCA[\"MSET_CCA\"] = make_pipeline(SSVEP_MsetCCA(freqs=freqs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n\nThe evaluation will return a DataFrame containing an accuracy score for\neach subject / session of the dataset, and for each pipeline.\n\nResults are saved into the database, so that if you add a new pipeline, it\nwill not run again the evaluation unless a parameter has changed. Results can\nbe overwritten if necessary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "overwrite = False  # set to True if we want to overwrite cached results\n\nevaluation = CrossSubjectEvaluation(\n    paradigm=paradigm, datasets=dataset, overwrite=overwrite\n)\nresults = evaluation.process(pipelines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter bank processing, determine the filter automatically from the\nstimulation frequency values of events.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evaluation_fb = CrossSubjectEvaluation(\n    paradigm=paradigm_fb, datasets=dataset, overwrite=overwrite\n)\nresults_fb = evaluation_fb.process(pipelines_fb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TRCA processing also relies on filter bank that is automatically designed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evaluation_TRCA = CrossSubjectEvaluation(\n    paradigm=paradigm_TRCA, datasets=dataset, overwrite=overwrite\n)\nresults_TRCA = evaluation_TRCA.process(pipelines_TRCA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MsetCCA processing\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evaluation_MSET_CCA = CrossSubjectEvaluation(\n    paradigm=paradigm_MSET_CCA, datasets=dataset, overwrite=overwrite\n)\nresults_MSET_CCA = evaluation_MSET_CCA.process(pipelines_MSET_CCA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After processing the four, we simply concatenate the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = pd.concat([results, results_fb, results_TRCA, results_MSET_CCA])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Results\n\nHere we display the results as stripplot, with a pointplot for error bar.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(facecolor=\"white\", figsize=[8, 4])\nsns.stripplot(\n    data=results,\n    y=\"score\",\n    x=\"pipeline\",\n    ax=ax,\n    jitter=True,\n    alpha=0.5,\n    zorder=1,\n    palette=\"Set1\",\n)\nsns.pointplot(data=results, y=\"score\", x=\"pipeline\", ax=ax, palette=\"Set1\")\nax.set_ylabel(\"Accuracy\")\nax.set_ylim(0.1, 0.6)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}