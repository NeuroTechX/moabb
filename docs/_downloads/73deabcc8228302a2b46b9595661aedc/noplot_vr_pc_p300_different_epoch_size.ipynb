{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Example of P300 classification with different epoch size.\n\n# Changing epoch size in P300 VR dataset\n\nThis example shows how to extract the epochs from the P300-VR dataset of a given\nsubject and then classify them using Riemannian Geometry framework for BCI.\nWe compare the scores in the VR and PC conditions, using different epoch size.\n\nThis example demonstrates the use of `get_block_repetition`, which allows\nto specify the experimental blocks and repetitions for analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Pedro Rodrigues <pedro.rodrigues01@gmail.com>\n# Modified by: Gregoire Cattan <gcattan@hotmail.fr>\n# License: BSD (3-clause)\n\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nfrom pyriemann.classification import MDM\nfrom pyriemann.estimation import ERPCovariances\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\n\nfrom moabb.datasets import Cattan2019_VR\nfrom moabb.paradigms import P300\n\n\nwarnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialization\n\n1) Create an instance of the dataset.\n2) Create an instance of a P300 paradigm.\n   By default filtering between 1-24 Hz\n   with epochs of length 1s.\n   In this example we will be modifying the length of the epochs, by\n   changing the `tmax` attribute of the paradigm.\n3) Encode categorical variable (Target/NonTarget) to numerical values.\n   We will be using label encoding.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = Cattan2019_VR()\nparadigm = P300()\nle = LabelEncoder().fit([\"Target\", \"NonTarget\"])\n\n# change this to include more subjects\nnsubjects = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation\n\nWe will perform a 3-folds validation for each combination of\ntmax, subjects and experimental conditions (VR or PC).\n\nNot all the data will be used for this validation.\nThe Cattan2019_VR dataset contains the data from a randomized experiment.\nWe will only be using the two first repetitions of the 12 experimental blocks.\nData will be selected thanks to the `get_block_repetition` method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Contains the score for all combination of tmax, subjects\n# and experimental condition (VR or PC).\nscores = []\n\n# Init 3-folds validation.\nkf = KFold(n_splits=3)\n\n# Select the first two repetitions.\nrepetitions = [1, 2]\n\n# Generate all possible arrangement with the 12 blocks.\nblocks = np.arange(1, 12 + 1)\n\n# run validation for each combination.\nfor tmax in [0.2, 1.0]:\n    paradigm.tmax = tmax\n\n    for subject in tqdm(dataset.subject_list[:nsubjects]):\n        # Note: here we are adding `tmax` to scores_subject,\n        # although `tmax` is defined outside the scope of this inner loop.\n        # The reason behind is to facilitate the conversion from array to dataframe at the end.\n        scores_subject = [tmax, subject]\n\n        for condition in [\"VR\", \"PC\"]:\n            print(f\"subject {subject}, {condition}, tmax {tmax}\")\n\n            # Rather than creating a new instance depending on the condition,\n            # let's change the attribute value to download the correct data.\n            dataset.virtual_reality = condition == \"VR\"\n            dataset.personal_computer = condition == \"PC\"\n\n            auc = []\n\n            # Split in training and testing blocks, and fit/predict.\n            # This loop will run 3 times as we are using a 3-folds validation\n            for train_idx, test_idx in kf.split(np.arange(12)):\n                # Note the use of the `get_block_repetition` method,\n                # to select the appropriate number of blocks and repetitions:\n                # - 8 blocks for training, 4 for testing\n                # - only the first two repetitions inside each blocks\n                X_train, y_train, _ = dataset.get_block_repetition(\n                    paradigm, [subject], blocks[train_idx], repetitions\n                )\n\n                X_test, y_test, _ = dataset.get_block_repetition(\n                    paradigm, [subject], blocks[test_idx], repetitions\n                )\n\n                # We use riemannian geometry processing techniques with MDM algorithm.\n                pipe = make_pipeline(ERPCovariances(estimator=\"lwf\"), MDM())\n                pipe.fit(X_train, y_train)\n                y_pred = pipe.predict(X_test)\n\n                # y_test and y_pred contains categorical variable (Target/NonTarget).\n                # To use a metric, we need to convert target information to numerical values.\n                y_test = le.transform(y_test)\n                y_pred = le.transform(y_pred)\n\n                # We use the roc_auc_score, which is a reliable metric for multi-class problem.\n                auc.append(roc_auc_score(y_test, y_pred))\n\n            # stock scores\n            scores_subject.append(np.mean(auc))\n\n        scores.append(scores_subject)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display of the data\n\nLet's transform or array to a dataframe.\nWe can then print it on the console, and\nplot the mean AUC as a function of the epoch length.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(scores, columns=[\"tmax\", \"subject\", \"VR\", \"PC\"])\n\nprint(df)\n\ndf.groupby(\"tmax\").mean().plot(\n    y=[\"VR\", \"PC\"], title=\"Mean AUC as a function of the epoch length\"\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}