{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tutorial 4: Creating a dataset class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Pedro L. C. Rodrigues, Sylvain Chevallier\n#\n# https://github.com/plcrodrigues/Workshop-MOABB-BCI-Graz-2019\n\nimport mne\nimport numpy as np\nfrom pyriemann.classification import MDM\nfrom pyriemann.estimation import Covariances\nfrom scipy.io import loadmat, savemat\nfrom sklearn.pipeline import make_pipeline\n\nfrom moabb.datasets import download as dl\nfrom moabb.datasets.base import BaseDataset\nfrom moabb.evaluations import WithinSessionEvaluation\nfrom moabb.paradigms import LeftRightImagery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating some Data\n\nTo illustrate the creation of a dataset class in MOABB, we first create an\nexample dataset saved in .mat file. It contains a single fake recording on\n8 channels lasting for 150 seconds (sampling frequency 256 Hz). We have\nincluded the script that creates this dataset and have uploaded it online.\nThe fake dataset is available on the\n[Zenodo website](https://sandbox.zenodo.org/record/369543)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def create_example_dataset():\n    \"\"\"Create a fake example for a dataset.\"\"\"\n    sfreq = 256\n    t_recording = 150\n    t_trial = 1  # duration of a trial\n    intertrial = 2  # time between end of a trial and the next one\n    n_chan = 8\n\n    x = np.zeros((n_chan + 1, t_recording * sfreq))  # electrodes + stimulus\n    stim = np.zeros(t_recording * sfreq)\n    t_offset = 1.0  # offset where the trials start\n    n_trials = 40\n\n    rep = np.linspace(0, 4 * t_trial, t_trial * sfreq)\n    signal = np.sin(2 * np.pi / t_trial * rep)\n    for n in range(n_trials):\n        label = n % 2 + 1  # alternate between class 0 and class 1\n        tn = int(t_offset * sfreq + n * (t_trial + intertrial) * sfreq)\n        stim[tn] = label\n        noise = 0.1 * np.random.randn(n_chan, len(signal))\n        x[:-1, tn : (tn + t_trial * sfreq)] = label * signal + noise\n    x[-1, :] = stim\n    return x, sfreq\n\n\n# Create the fake data\nfor subject in [1, 2, 3]:\n    x, fs = create_example_dataset()\n    filename = \"subject_\" + str(subject).zfill(2) + \".mat\"\n    mdict = {}\n    mdict[\"x\"] = x\n    mdict[\"fs\"] = fs\n    savemat(filename, mdict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a Dataset Class\n\nWe will create now a dataset class using the fake data simulated with the\ncode from above. For this, we first need to import the right classes from\nMOABB:\n\n- ``dl`` is a very useful script that downloads automatically a dataset online\n  if it is not yet available in the user's computer. The script knows where\n  to download the files because we create a global variable telling the URL\n  where to fetch the data.\n- ``BaseDataset`` is the basic class that we overload to create our dataset.\n\nThe global variable with the dataset's URL should specify an online\nrepository where all the files are stored.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ExampleDataset_URL = \"https://sandbox.zenodo.org/record/369543/files/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ``ExampleDataset`` needs to implement only 3 functions:\n\n- ``__init__`` for indicating the parameter of the dataset\n- ``_get_single_subject_data`` to define how to process the data once they\n  have been downloaded\n- ``data_path`` to define how the data are downloaded.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class ExampleDataset(BaseDataset):\n    \"\"\"Dataset used to exemplify the creation of a dataset class in MOABB.\n\n    The data samples have been simulated and has no physiological\n    meaning whatsoever.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(\n            subjects=[1, 2, 3],\n            sessions_per_subject=1,\n            events={\"left_hand\": 1, \"right_hand\": 2},\n            code=\"ExampleDataset\",\n            interval=[0, 0.75],\n            paradigm=\"imagery\",\n            doi=\"\",\n        )\n\n    def _get_single_subject_data(self, subject):\n        \"\"\"Return data for a single subject.\"\"\"\n        file_path_list = self.data_path(subject)\n\n        data = loadmat(file_path_list[0])\n        x = data[\"x\"]\n        fs = data[\"fs\"]\n        ch_names = [\"ch\" + str(i) for i in range(8)] + [\"stim\"]\n        ch_types = [\"eeg\" for i in range(8)] + [\"stim\"]\n        info = mne.create_info(ch_names, fs, ch_types)\n        raw = mne.io.RawArray(x, info)\n\n        sessions = {}\n        sessions[\"0\"] = {}\n        sessions[\"0\"][\"0\"] = raw\n        return sessions\n\n    def data_path(\n        self, subject, path=None, force_update=False, update_path=None, verbose=None\n    ):\n        \"\"\"Download the data from one subject.\"\"\"\n        if subject not in self.subject_list:\n            raise (ValueError(\"Invalid subject number\"))\n\n        url = \"{:s}subject_0{:d}.mat\".format(ExampleDataset_URL, subject)\n        path = dl.data_dl(url, \"ExampleDataset\")\n        return [path]  # it has to return a list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the ExampleDataset\n\nNow that the `ExampleDataset` is defined, it could be instantiated directly.\nThe rest of the code follows the steps described in the previous tutorials.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = ExampleDataset()\n\nparadigm = LeftRightImagery()\nX, labels, meta = paradigm.get_data(dataset=dataset, subjects=[1])\n\nevaluation = WithinSessionEvaluation(\n    paradigm=paradigm, datasets=dataset, overwrite=False, suffix=\"newdataset\"\n)\npipelines = {}\npipelines[\"MDM\"] = make_pipeline(Covariances(\"oas\"), MDM(metric=\"riemann\"))\nscores = evaluation.process(pipelines)\n\nprint(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pushing on MOABB Github\n\nIf you want to make your dataset available to everyone, you could upload\nyour data on public server (like Zenodo or Figshare) and signal that you\nwant to add your dataset to MOABB in the  [dedicated issue](https://github.com/NeuroTechX/moabb/issues/1).  # noqa: E501\nYou could then follow the instructions on [how to contribute](https://github.com/NeuroTechX/moabb/blob/master/CONTRIBUTING.md)  # noqa: E501\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}