{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Within Session P300 with Learning Curve\n\nThis example shows how to perform a within session analysis while also\ncreating learning curves for a P300 dataset.\nAdditionally, we will evaluate external code. Make sure to have tdlda installed, which\ncan be found in requirements_external.txt\n\nWe will compare three pipelines :\n\n- Riemannian geometry\n- Jumping Means-based Linear Discriminant Analysis\n- Time-Decoupled Linear Discriminant Analysis\n\nWe will use the P300 paradigm, which uses the AUC as metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Jan Sosulski\n#\n# License: BSD (3-clause)\n\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom pyriemann.estimation import XdawnCovariances\nfrom pyriemann.tangentspace import TangentSpace\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.pipeline import make_pipeline\nfrom tdlda import TimeDecoupledLda\nfrom tdlda import Vectorizer as JumpingMeansVectorizer\n\nimport moabb\nfrom moabb.datasets import BNCI2014009\nfrom moabb.evaluations import WithinSessionEvaluation\nfrom moabb.paradigms import P300\n\n\n# getting rid of the warnings about the future (on s'en fout !)\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\nwarnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n\n\nmoabb.set_log_level(\"info\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create pipelines\n\nPipelines must be a dict of sklearn pipeline transformer.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "processing_sampling_rate = 128\npipelines = {}\n\n# We have to do this because the classes are called 'Target' and 'NonTarget'\n# but the evaluation function uses a LabelEncoder, transforming them\n# to 0 and 1\nlabels_dict = {\"Target\": 1, \"NonTarget\": 0}\n\n# Riemannian geometry based classification\npipelines[\"RG+LDA\"] = make_pipeline(\n    XdawnCovariances(nfilter=5, estimator=\"lwf\", xdawn_estimator=\"scm\"),\n    TangentSpace(),\n    LDA(solver=\"lsqr\", shrinkage=\"auto\"),\n)\n\n# Simple LDA pipeline using averaged feature values in certain time intervals\njumping_mean_ivals = [\n    [0.10, 0.139],\n    [0.14, 0.169],\n    [0.17, 0.199],\n    [0.20, 0.229],\n    [0.23, 0.269],\n    [0.27, 0.299],\n    [0.30, 0.349],\n    [0.35, 0.409],\n    [0.41, 0.449],\n    [0.45, 0.499],\n]\njmv = JumpingMeansVectorizer(\n    fs=processing_sampling_rate, jumping_mean_ivals=jumping_mean_ivals\n)\n\npipelines[\"JM+LDA\"] = make_pipeline(jmv, LDA(solver=\"lsqr\", shrinkage=\"auto\"))\n\n# Time-decoupled Covariance classifier, needs information about number of\n# channels and time intervals\nc = TimeDecoupledLda(N_channels=16, N_times=10)\n# TD-LDA needs to know about the used jumping means intervals\nc.preproc = jmv\npipelines[\"JM+TD-LDA\"] = make_pipeline(jmv, c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n\nWe define the paradigm (P300) and use the BNCI 2014-009 dataset for it.\nThe evaluation will return a dataframe containing AUCs for each permutation\nand dataset size.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "paradigm = P300(resample=processing_sampling_rate)\ndataset = BNCI2014009()\n# Remove the slicing of the subject list to evaluate multiple subjects\ndataset.subject_list = dataset.subject_list[0:1]\ndatasets = [dataset]\noverwrite = True  # set to True if we want to overwrite cached results\ndata_size = dict(policy=\"ratio\", value=np.geomspace(0.02, 1, 6))\n# When the training data is sparse, peform more permutations than when we have a lot of data\nn_perms = np.floor(np.geomspace(20, 2, len(data_size[\"value\"]))).astype(int)\nprint(n_perms)\n# Guarantee reproducibility\nnp.random.seed(7536298)\nevaluation = WithinSessionEvaluation(\n    paradigm=paradigm,\n    datasets=datasets,\n    data_size=data_size,\n    n_perms=n_perms,\n    suffix=\"examples_lr\",\n    overwrite=overwrite,\n)\n\n\nresults = evaluation.process(pipelines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Results\n\nHere we plot the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(facecolor=\"white\", figsize=[8, 4])\n\nn_subs = len(dataset.subject_list)\n\nif n_subs > 1:\n    r = results.groupby([\"pipeline\", \"subject\", \"data_size\"]).mean().reset_index()\nelse:\n    r = results\n\nsns.pointplot(data=r, x=\"data_size\", y=\"score\", hue=\"pipeline\", ax=ax, palette=\"Set1\")\n\nerrbar_meaning = \"subjects\" if n_subs > 1 else \"permutations\"\ntitle_str = f\"Errorbar shows Mean-CI across {errbar_meaning}\"\nax.set_xlabel(\"Amount of training samples\")\nax.set_ylabel(\"ROC AUC\")\nax.set_title(title_str)\nfig.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}