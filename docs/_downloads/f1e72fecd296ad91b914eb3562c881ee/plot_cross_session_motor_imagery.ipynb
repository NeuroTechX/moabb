{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Cross-Session Motor Imagery\n\nThis example show how to perform a cross session motor imagery analysis on the\nvery popular dataset 2a from the BCI competition IV.\n\nWe will compare two pipelines :\n\n- CSP+LDA\n- Riemannian Geometry+Logistic Regression\n\nWe will use the LeftRightImagery paradigm. This will restrict the analysis\nto two classes (left hand versus right hand) and use AUC as metric.\n\nThe cross session evaluation context will evaluate performance using a leave\none session out cross-validation. For each session in the dataset, a model\nis trained on every other session and performance are evaluated on the current\nsession.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Alexandre Barachant <alexandre.barachant@gmail.com>\n#          Sylvain Chevallier <sylvain.chevallier@uvsq.fr>\n#\n# License: BSD (3-clause)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mne.decoding import CSP\nfrom pyriemann.estimation import Covariances\nfrom pyriemann.tangentspace import TangentSpace\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\n\nimport moabb\nfrom moabb.datasets import BNCI2014001\nfrom moabb.evaluations import CrossSessionEvaluation\nfrom moabb.paradigms import LeftRightImagery\n\n\nmoabb.set_log_level(\"info\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Pipelines\n\nPipelines must be a dict of sklearn pipeline transformer.\n\nThe CSP implementation is based on the MNE implementation. We selected 8 CSP\ncomponents, as usually done in the literature.\n\nThe Riemannian geometry pipeline consists in covariance estimation, tangent\nspace mapping and finally a logistic regression for the classification.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipelines = {}\n\npipelines[\"CSP+LDA\"] = make_pipeline(CSP(n_components=8), LDA())\n\npipelines[\"RG+LR\"] = make_pipeline(\n    Covariances(), TangentSpace(), LogisticRegression(solver=\"lbfgs\")\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n\nWe define the paradigm (LeftRightImagery) and the dataset (BNCI2014001).\nThe evaluation will return a DataFrame containing a single AUC score for\neach subject / session of the dataset, and for each pipeline.\n\nResults are saved into the database, so that if you add a new pipeline, it\nwill not run again the evaluation unless a parameter has changed. Results can\nbe overwritten if necessary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "paradigm = LeftRightImagery()\n# Because this is being auto-generated we only use 2 subjects\ndataset = BNCI2014001()\ndataset.subject_list = dataset.subject_list[:2]\ndatasets = [dataset]\noverwrite = False  # set to True if we want to overwrite cached results\nevaluation = CrossSessionEvaluation(\n    paradigm=paradigm, datasets=datasets, suffix=\"examples\", overwrite=overwrite\n)\n\nresults = evaluation.process(pipelines)\n\nprint(results.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Results\n\nHere we plot the results. We first make a pointplot with the average\nperformance of each pipeline across session and subjects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=[8, 4], sharey=True)\n\nsns.stripplot(\n    data=results,\n    y=\"score\",\n    x=\"pipeline\",\n    ax=axes[0],\n    jitter=True,\n    alpha=0.5,\n    zorder=1,\n    palette=\"Set1\",\n)\nsns.pointplot(data=results, y=\"score\", x=\"pipeline\", ax=axes[0], zorder=1, palette=\"Set1\")\n\naxes[0].set_ylabel(\"ROC AUC\")\naxes[0].set_ylim(0.5, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The second plot is a paired scatter plot. Each point representing the score\nof a single session. An algorithm will outperform another is most of the\npoints are in its quadrant.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "paired = results.pivot_table(\n    values=\"score\", columns=\"pipeline\", index=[\"subject\", \"session\"]\n)\npaired = paired.reset_index()\n\nsns.regplot(data=paired, y=\"RG+LR\", x=\"CSP+LDA\", ax=axes[1], fit_reg=False)\naxes[1].plot([0, 1], [0, 1], ls=\"--\", c=\"k\")\naxes[1].set_xlim(0.5, 1)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}