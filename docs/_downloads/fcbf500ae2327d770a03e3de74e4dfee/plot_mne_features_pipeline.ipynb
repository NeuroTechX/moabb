{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Pipelines using the mne-features library\n\nThis example shows how to evaluate a pipeline constructed using the\nmne-features library [1]_. This library provides sklearn compatible\nfeature extractors for M/EEG data. These features\ncan be used directly in your pipelines.\n\nA list of available features can be found\nin [the docs](https://mne.tools/mne-features/api.html).\n\nBe sure to install mne-features by running ``pip install mne-features``.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Alexander de Ranitz <alexanderderanitz@gmail.com>\n#          Luuk Neervens <luuk.neervens@ru.nl>\n#          Charlynn van Osch <charlynn.vanosch@ru.nl>\n#\n# License: BSD (3-clause)\n\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport mne\nimport seaborn as sns\nfrom mne_features.feature_extraction import FeatureExtractor\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.pipeline import make_pipeline\n\nimport moabb\nfrom moabb.datasets import BNCI2014_001\nfrom moabb.evaluations import WithinSessionEvaluation\nfrom moabb.paradigms import LeftRightImagery\n\n\nmne.set_log_level(\"CRITICAL\")\nmoabb.set_log_level(\"info\")\nwarnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Pipelines using mne-features\n\nHere, we closely follow Tutorial 3, but we create pipelines using features\nextracted using the mne-features library [1]_. We instantiate the three different\nclassiciation pipelines to be considered in the analysis.\nSee the mne-features docs to learn more about the available features:\nhttps://mne.tools/mne-features/api.html#api-documentation\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Details\nWe will use the [FeatureExtractor](https://mne.tools/mne-features/generated/mne_features.feature_extraction.FeatureExtractor.html)_\nto compute features. Here, we select two simple features:\n``variance`` and ``ptp_amp`` (peak-to-peak amplitude).\n\n**Variance:**\nComputed per channel (``c``). It measures the spread of the signal values\n(samples in vector ``x``) around their average value (``mean(x)``).\nIt involves summing the squared differences between each sample and the mean,\nthen normalizing, at mne-features, it is the number of samples minus 1.\n\n**Peak-to-Peak Amplitude (ptp_amp):**\nComputed per channel (``c``). This is simply the difference between the\nmaximum and minimum signal values found within that channel's data vector ``x``.\nFormula: ``ptp_amp(c) = max(x) - min(x)``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sfreq = 250.0  # sampling frequency used in the datasets below\n\nvariance = FeatureExtractor(sfreq, [\"variance\"])\nptp_amp = FeatureExtractor(sfreq, [\"ptp_amp\"])\n\n# We can also extract several features by passing more than one feature.\nboth = FeatureExtractor(sfreq, [\"ptp_amp\", \"variance\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipelines with ``FeatureExtractor``\nThe ``FeatureExtractor`` from mne-features is scikit-learn compatible and\ncan therefore be used directly in our pipelines. Here, these transformer\nsteps perform feature extraction, reducing the dimensionality of the data.\nWe train an LDA classifier to classify our data as left- or right hand\nbased on the extracted signal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipelines = {}\npipelines[\"var+LDA\"] = make_pipeline(variance, LDA())\npipelines[\"ptp_amp+LDA\"] = make_pipeline(ptp_amp, LDA())\npipelines[\"var+ptp_amp+LDA\"] = make_pipeline(both, LDA())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The rest is the same as in previous tutorials!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasets = [BNCI2014_001()]\nsubj = [1, 2, 3]\nfor d in datasets:\n    d.subject_list = subj\nparadigm = LeftRightImagery()\nevaluation = WithinSessionEvaluation(\n    paradigm=paradigm, datasets=datasets, overwrite=False\n)\nresults = evaluation.process(pipelines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting Results\n\nThe following plot shows a comparison of the three classification pipelines\nfor each subject. We can see that subjects 1 and 3, the pipeline using\nonly the variance performs best. Perhaps this is because the variance is\nless sensitive to noise than the peak-to-peak amplitude, as the variance\nis computed over the whole epoch, whereas the peak-to-peak amplitude\nonly considers the two most extreme data points (which could be outliers).\nFor subject 2, the peak-to-peak amplitude pipeline works best.\n\nIn general, the pipeline using both peak-to-peak amplitude and variance\nhas a mediocre performance, never beating the best single-feature pipeline\nin this experiment. This might be because using both\nvariance and peak-to-peak amplitude increases the data dimensionality,\nwithout adding a lot of new information, resulting in increased overfitting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results[\"subj\"] = [str(resi).zfill(2) for resi in results[\"subject\"]]\ng = sns.catplot(\n    kind=\"bar\",\n    x=\"score\",\n    y=\"subj\",\n    hue=\"pipeline\",\n    col=\"dataset\",\n    height=12,\n    aspect=0.5,\n    data=results,\n    orient=\"h\",\n    palette=\"viridis\",\n)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n.. [1] Schiratti, J. B., Le Douget, J. E., Le Van Quyen, M., Essid, S., & Gramfort, A. (2018, April). An ensemble learning approach to detect epileptic seizures from long intracranial EEG recordings. In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 856-860). IEEE.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}