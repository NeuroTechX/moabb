{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Within Session Motor Imagery with Learning Curve\n\nThis example shows how to perform a within session motor imagery analysis on the\nvery popular dataset 2a from the BCI competition IV.\n\nWe will compare two pipelines :\n\n- CSP + LDA\n- Riemannian Geometry + Logistic Regression\n\nWe will use the LeftRightImagery paradigm. This will restrict the analysis\nto two classes (left- vs right-hand) and use AUC as metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Original author: Alexandre Barachant <alexandre.barachant@gmail.com>\n# Learning curve modification: Jan Sosulski\n#\n# License: BSD (3-clause)\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom mne.decoding import CSP\nfrom pyriemann.estimation import Covariances\nfrom pyriemann.tangentspace import TangentSpace\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\n\nimport moabb\nfrom moabb.datasets import BNCI2014001\nfrom moabb.evaluations import WithinSessionEvaluation\nfrom moabb.paradigms import LeftRightImagery\n\n\nmoabb.set_log_level(\"info\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Pipelines\n\nPipelines must be a dict of sklearn pipeline transformer.\n\nThe CSP implementation from MNE is used. We selected 8 CSP components, as\nusually done in the litterature.\n\nThe Riemannian geometry pipeline consists in covariance estimation, tangent\nspace mapping and finally a logistic regression for the classification.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipelines = {}\n\npipelines[\"CSP+LDA\"] = make_pipeline(\n    CSP(n_components=8), LDA(solver=\"lsqr\", shrinkage=\"auto\")\n)\n\npipelines[\"RG+LR\"] = make_pipeline(\n    Covariances(), TangentSpace(), LogisticRegression(solver=\"lbfgs\")\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n\nWe define the paradigm (LeftRightImagery) and the dataset (BNCI2014001).\nThe evaluation will return a DataFrame containing a single AUC score for\neach subject / session of the dataset, and for each pipeline.\n\nResults are saved into the database, so that if you add a new pipeline, it\nwill not run again the evaluation unless a parameter has changed. Results can\nbe overwritten if necessary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "paradigm = LeftRightImagery()\ndataset = BNCI2014001()\ndataset.subject_list = dataset.subject_list[:1]\ndatasets = [dataset]\noverwrite = True  # set to True if we want to overwrite cached results\n# Evaluate for a specific number of training samples per class\ndata_size = dict(policy=\"per_class\", value=np.array([5, 10, 30, 50]))\n# When the training data is sparse, peform more permutations than when we have a lot of data\nn_perms = np.floor(np.geomspace(20, 2, len(data_size[\"value\"]))).astype(int)\nevaluation = WithinSessionEvaluation(\n    paradigm=paradigm,\n    datasets=datasets,\n    suffix=\"examples\",\n    overwrite=overwrite,\n    data_size=data_size,\n    n_perms=n_perms,\n)\n\nresults = evaluation.process(pipelines)\n\nprint(results.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Results\n\nWe plot the accuracy as a function of the number of training samples, for\neach pipeline\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(facecolor=\"white\", figsize=[8, 4])\n\nn_subs = len(dataset.subject_list)\n\nif n_subs > 1:\n    r = results.groupby([\"pipeline\", \"subject\", \"data_size\"]).mean().reset_index()\nelse:\n    r = results\n\nsns.pointplot(data=r, x=\"data_size\", y=\"score\", hue=\"pipeline\", ax=ax, palette=\"Set1\")\n\nerrbar_meaning = \"subjects\" if n_subs > 1 else \"permutations\"\ntitle_str = f\"Errorbar shows Mean-CI across {errbar_meaning}\"\nax.set_xlabel(\"Amount of training samples\")\nax.set_ylabel(\"ROC AUC\")\nax.set_title(title_str)\nfig.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}